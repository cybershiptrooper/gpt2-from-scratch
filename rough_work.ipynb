{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from model.attention import *\n",
    "from model.embeddings import *\n",
    "from model.layer_norm  import *\n",
    "from model.transformer_mlp import *\n",
    "from model.transformer_block import *\n",
    "from model.transformer_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.rand((2, 3, 4)) # batch x words x d_model\n",
    "Wk = torch.rand(4, 4) #d_model x d_model\n",
    "Wq = torch.rand(4, 4) #d_model x d_model\n",
    "K = (Wk @ k.transpose(-2, -1) ).transpose(-2, -1)\n",
    "Q = (Wq @ k.transpose(-2, -1) ).transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.8758, 1.3845, 1.8956, 1.7097],\n",
       "         [1.0354, 0.7647, 1.3465, 1.2667],\n",
       "         [1.1589, 1.7530, 2.5708, 2.3320]]),\n",
       " tensor([[0.8823, 1.5489, 1.6262, 1.3652],\n",
       "         [0.6445, 0.8173, 1.2710, 0.6885],\n",
       "         [0.7545, 1.4069, 1.8011, 1.5804]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[0], K[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.3337,  5.2824,  8.7249],\n",
       "        [ 6.0169,  3.8759,  6.2843],\n",
       "        [11.1018,  7.0527, 11.6566]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q@(K.transpose(-2, -1)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2824)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[0][0]@K[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.mean(dim=-1, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
